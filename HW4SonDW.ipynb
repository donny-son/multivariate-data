{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2, f\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "try:\n",
    "    import termplotlib as tpl\n",
    "except Exception as e:\n",
    "    print(f\"termploblib is not installed.\\nUsing matplotlib as default.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 \n",
    "\n",
    "> Write a Python code to implement Hotellingâ€™s T2 test of a mean vector. (use p-value for testing).\n",
    "\n",
    "Hotelling's test is implemented as a method for the `MultivariateData` object as `hotellings_t_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateData:\n",
    "    \"\"\"Object for processing multivariate data.\n",
    "\n",
    "    params\n",
    "    ------\n",
    "    src: input matrix of shape (n:int, p:int) where n is the sample size and p is the number of dependent variables\n",
    "        np.ndarray\n",
    "\n",
    "    methods\n",
    "    -------\n",
    "    _get_mean_vector: gets the mean vector along the features\n",
    "        np.array\n",
    "\n",
    "    _get_cov_mat: gets the covariance matrix in (p by p).\n",
    "        np.array\n",
    "\n",
    "    _generalized_squared_distance: gets list of squared distance by dimension n.\n",
    "        list\n",
    "\n",
    "    _get_qq_tuples: gets the list of tuples of the qq pair for the chisquare distribution with df=p\n",
    "        list\n",
    "\n",
    "    draw_qqplot: draws the plot by using matplotlib\n",
    "\n",
    "    hotellings_t_test: performs a Hotelling's T^2 test with a given mu vector and significance level\n",
    "        float\n",
    "        \n",
    "    confidence_ellipsoid_info: Calculates the axis and the length of the ellipsoide of the multivariate data given a significance level.\n",
    "        dict\n",
    "    \n",
    "    simultaneous_confidence_interval: Calculates the simultaneous confidence interval given a transformation vector\n",
    "        tuple\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, src) -> None:\n",
    "        self.src = self._numpy_coersion(src)\n",
    "        self.n, self.p = self.src.shape\n",
    "        self.mean_vector = self._get_mean_vector()\n",
    "        self.cov_matrix = self._get_cov_mat()\n",
    "\n",
    "    @staticmethod\n",
    "    def _numpy_coersion(data) -> np.array:\n",
    "        # coerce pandas or other iterative data to numpy array.\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            try:\n",
    "                result = np.array(data)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"{data.__class__} cannot be coerced to Numpy array!\\nERROR:{e}\")\n",
    "            return result\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    def _get_mean_vector(self) -> np.array:\n",
    "        return (np.mean(self.src, axis=0))\n",
    "\n",
    "    def _get_cov_mat(self) -> np.array:\n",
    "        result = np.cov(self.src.transpose())\n",
    "        assert result.shape == (self.p, self.p)\n",
    "        return result\n",
    "\n",
    "    def _generalized_squared_distance(self) -> list:\n",
    "        result = []\n",
    "        inv_cov = np.linalg.inv(self.cov_matrix)\n",
    "        for row in self.src:\n",
    "            diff = row - self.mean_vector\n",
    "            # numpy broadcasting\n",
    "            result.append(np.matmul(np.matmul(diff, inv_cov), diff))\n",
    "        assert len(result) == self.n\n",
    "        return result\n",
    "\n",
    "    def _get_qq_tuples(self) -> list:\n",
    "        result = []\n",
    "        sorted_general_distance = sorted(self._generalized_squared_distance())\n",
    "        for i, x in enumerate(sorted_general_distance):\n",
    "            x_probability_value = (i+1 - 0.5) / self.n\n",
    "            q_value = chi2.ppf(x_probability_value, self.p)\n",
    "            result.append(\n",
    "                (q_value, x)\n",
    "            )\n",
    "        return result\n",
    "\n",
    "    def draw_qqplot(self, terminal=False):\n",
    "        qq_tuples = self._get_qq_tuples()\n",
    "        x = [x for x, _ in qq_tuples]\n",
    "        y = [y for _, y in qq_tuples]\n",
    "        if terminal:\n",
    "            fig = tpl.figure()\n",
    "            fig.plot(x, y, width=60, height=20)\n",
    "            fig.show()\n",
    "        else:\n",
    "            plt.scatter(x, y)\n",
    "            plt.show()\n",
    "\n",
    "    def hotellings_t_test(self, mu_vector_null, significance=0.05, method=\"p\"):\n",
    "        \"\"\"Performs Hotellings test for mean comparison, via adjusted F distribution\n",
    "\n",
    "        Args:\n",
    "            mu_vector_null ([int, float]): vector of mean under the null hypothesis\n",
    "            significance (float, optional): Significance level. Defaults to 0.05.\n",
    "            method (str, optional): Method of testing. Either 'p' or 'critical'. Defaults to \"p\".\n",
    "        \"\"\"\n",
    "        assert (isinstance(mu_vector_null, list)\n",
    "                or isinstance(mu_vector_null, np.ndarray))\n",
    "        assert (0 < significance < 1)\n",
    "        inv_cov = np.linalg.inv(self.cov_matrix)\n",
    "        diff = self.mean_vector - mu_vector_null\n",
    "        t_2_statistic = self.n * np.matmul(np.matmul(diff, inv_cov), diff)\n",
    "        critical_value = ((self.n - 1) * self.p)/(self.n-self.p) * \\\n",
    "            f.ppf(significance, self.p, self.n - self.p)\n",
    "        f_statistic = ((self.n - self.p) * t_2_statistic) / \\\n",
    "            ((self.n-1) * self.p)\n",
    "        p_value = 1-f.cdf(f_statistic, self.p, self.n - self.p)\n",
    "        print(f\"---------------------HOTELLING'S T^2 TEST----------------------\")\n",
    "        print(\n",
    "            f\"Null Hypothesis:\\n  Mean vector {self.mean_vector}\\n  is equal to {np.array(mu_vector_null)}\")\n",
    "        print(f\"T^2 statistic: {t_2_statistic}\")\n",
    "        print(f\"F statistic: {f_statistic}\")\n",
    "\n",
    "        print(f\"Significance(alpha): {significance}\")\n",
    "\n",
    "        if method == 'p':\n",
    "            print(f\"P-value: {p_value}\")\n",
    "        elif method == 'critical':\n",
    "            print(\n",
    "                f\"Critical Value: {critical_value}\")\n",
    "\n",
    "        if p_value < significance:\n",
    "            print(f\"Conclusion: REJECT the null hypothesis\")\n",
    "        else:\n",
    "            print(f\"Conclusion: DO NOT reject the null hypothesis\")\n",
    "        print(f\"---------------------------------------------------------------\")\n",
    "\n",
    "    def confidence_ellipsoid_info(self, significance=0.05) -> dict:\n",
    "        \"\"\"Calculates the axis and the length of the ellipsoide of the multivariate data.\n",
    "\n",
    "        Args:\n",
    "            significance (float, optional): [Level of significance]. Defaults to 0.05.\n",
    "\n",
    "        Returns:\n",
    "            dict: integer keys will be the axes in the descending order. Each key has two keys(\"axis\", \"length\")\n",
    "                  axis denotes the direction of the ellipsoide\n",
    "                  length denotes the length of the axis.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(self.cov_matrix)\n",
    "        for i, v in enumerate(eigenvalues):\n",
    "            conf_half_len = np.sqrt(v) * np.sqrt((self.n - 1) * self.p * f.ppf(\n",
    "                significance, self.p, self.n - self.p) / (self.n * (self.n - self.p)))\n",
    "            conf_axe_abs = conf_half_len * eigenvectors[i]\n",
    "            result[i] = {\n",
    "                \"axis\": (conf_axe_abs, -conf_axe_abs),\n",
    "                \"length\": conf_half_len * 2\n",
    "            }\n",
    "        return result\n",
    "\n",
    "    def simultaneous_confidence_interval(self, vector, significance=0.05, large_sample=False) -> tuple:\n",
    "        \"\"\"Calculates the simultaneous confidence interval given a transformation vector and a significance level.\n",
    "             The default method would be not assuming the data as a large sample.\n",
    "\n",
    "        Args:\n",
    "           vector (list or ndarray): [The transformation vector].\n",
    "           significance (float, optional): [Level of significance]. Defaults to 0.05.\n",
    "           large_sample (bool, optional): [Use large sample assumptions]. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "           tuple: (lowerbound: float, upperbound: float)\n",
    "        \"\"\"\n",
    "        assert len(vector) == self.p\n",
    "        if not isinstance(vector, np.ndarray):\n",
    "            vec = np.array(vector)\n",
    "        else:\n",
    "            vec = vector\n",
    "        if not large_sample:\n",
    "            conf_width = np.sqrt(\n",
    "                self.p * (self.n - 1) * f.ppf(significance, self.p, self.n - self.p) * vec.dot(self.cov_matrix).dot(vec) / (self.n * (self.n - self.p)))\n",
    "            t_mean = vec.dot(self.mean_vector)\n",
    "            return (t_mean - conf_width, t_mean + conf_width)\n",
    "        else:\n",
    "            conf_width = np.sqrt(chi2.ppf(significance, self.p) *\n",
    "                                 vec.dot(self.cov_matrix).dot(vec)/self.n)\n",
    "            t_mean = vec.dot(self.mean_vector)\n",
    "            return (t_mean - conf_width, t_mean + conf_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "## a.\n",
    "Testing `college.DAT` with the implemented function above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------HOTELLING'S T^2 TEST----------------------\n",
      "Null Hypothesis:\n",
      "  Mean vector [526.5862069   54.68965517  25.12643678]\n",
      "  is equal to [500  50  30]\n",
      "T^2 statistic: 223.3101756848916\n",
      "F statistic: 72.70563859508097\n",
      "Significance(alpha): 0.05\n",
      "P-value: 1.1102230246251565e-16\n",
      "Conclusion: REJECT the null hypothesis\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "college_dat = pd.read_csv(\"college.DAT\", delim_whitespace=True, header=None)\n",
    "college_dat.columns = [\"ssh\", \"vrbl\", \"sci\"]\n",
    "cd = MultivariateData(college_dat)\n",
    "null_hypothesis_mean_vector = [500, 50, 30]\n",
    "cd.hotellings_t_test(null_hypothesis_mean_vector, significance=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "## b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multivariate as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.base.HolderTuple'>\n",
       "statistic = 72.70563859508101\n",
       "pvalue = 2.828097062464791e-23\n",
       "df = (3, 84)\n",
       "t2 = 223.3101756848917\n",
       "distr = F\n",
       "tuple = (72.70563859508101, 2.828097062464791e-23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv.test_mvmean(cd.src - null_hypothesis_mean_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result derived from the `statsmodel` package is consistent with my custom function. Note that even though the pvalue seems different, in reality it is not. This is due to the fact that computer software cannot accurately represent `float` this small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "## c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'axis': (array([-4.89424684, -0.51080087, -0.18371125]),\n",
      "              array([4.89424684, 0.51080087, 0.18371125])),\n",
      "     'length': 9.848516527874517},\n",
      " 1: {'axis': (array([-0.0530798 ,  0.51035257, -0.00491465]),\n",
      "              array([ 0.0530798 , -0.51035257,  0.00491465])),\n",
      "     'length': 1.0262579964587029},\n",
      " 2: {'axis': (array([-0.00934886,  0.00138893,  0.24520082]),\n",
      "              array([ 0.00934886, -0.00138893, -0.24520082])),\n",
      "     'length': 0.49076582646381417}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cd.confidence_ellipsoid_info(significance=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "## d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find the simultaneous confidence interval for $\\mu_1 -2\\mu_2 + \\mu_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438.1245590084046, 446.5421076582621)\n"
     ]
    }
   ],
   "source": [
    "print(cd.simultaneous_confidence_interval([1, -2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "## a.\n",
    "\n",
    "> Find the simultaneous confidence interval for $\\mu_1 + 2\\mu_2 - \\mu_3 - 2\\mu_4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341.5131034172878, 550.6868965827111)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "stiff = pd.read_csv('stiff.DAT',\n",
    "                    header=None, delim_whitespace=True)\n",
    "stiff.columns = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "\n",
    "stf = MultivariateData(stiff)\n",
    "print(stf.simultaneous_confidence_interval([1, 2, -1, -2, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.\n",
    "> Repeating the above step with large sample assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347.2745304989698, 544.925469501029)\n"
     ]
    }
   ],
   "source": [
    "print(stf.simultaneous_confidence_interval(\n",
    "    [1, 2, -1, -2, 0], large_sample=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the confidence interval slightly shortened compared to the above result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "7977c45806cdf3e0dd41dd5ac4f02653cd6b201ea1f52a9753d7a8820e467c8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
